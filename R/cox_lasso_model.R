library(glmnet)
library(survival)
#' Cox Lasso Model Implementation
#'
#' @description
#' Implements Cox Lasso regression using the glmnet package with cross-validation
#' for optimal lambda parameter selection. This serves as a baseline method for
#' comparison with TransCox models.
#'
#' @param train_data A data.frame containing the training dataset with survival
#'   times, event status, and covariates.
#' @param cov_names A character vector specifying the names of covariates to be
#'   included in the model.
#' @param alpha Numeric. Elastic Net mixing parameter. 1 = Lasso (L1 penalty),
#'   0 = Ridge (L2 penalty). Default is 1.
#' @param nfolds Integer. Number of folds for cross-validation. Default is 10.
#' @param lambda_seq Numeric vector. Sequence of lambda values for regularization.
#'   If NULL, will be automatically generated by glmnet. Default is NULL.
#' @param verbose Logical. Whether to display training progress information.
#'   Default is TRUE.
#'
#' @return A list containing the following components:
#' \describe{
#'   \item{model}{The fitted glmnet model object}
#'   \item{cv_model}{The cross-validation results}
#'   \item{lambda_min}{The lambda value that minimizes cross-validation error}
#'   \item{lambda_1se}{The lambda value within 1 standard error of minimum}
#'   \item{coefficients}{The estimated coefficients at lambda_min}
#'   \item{active_vars}{Names of variables with non-zero coefficients}
#' }
#'
#' @examples
#' \dontrun{
#' # Generate example data
#' data <- generate_sparse_survival_data(n_main = 100, p = 50)
#'
#' # Train Cox Lasso model
#' lasso_model <- train_cox_lasso(
#'   train_data = data$prim_data,
#'   cov_names = paste0("X", 1:50)
#' )
#'
#' # View results
#' print(lasso_model$lambda_min)
#' print(lasso_model$active_vars)
#' }
#'
#' @export
train_cox_lasso <- function(train_data,
                           cov_names,
                           alpha = 1,
                           nfolds = 10,
                           lambda_seq = NULL,
                           verbose = TRUE) {

    if (verbose) cat("Starting Cox Lasso model training...\n")

    # Prepare data
    X <- as.matrix(train_data[, cov_names])
    # Ensure event status is correctly encoded: status=2 indicates event, status=1 indicates censoring
    # Surv function expects 0/1 encoding, so convert to status==2
    y <- Surv(train_data$time, train_data$status == 2)

    # Train model
    if (verbose) {
        cat("Training samples:", nrow(X), "\n")
        cat("Features:", ncol(X), "\n")
        cat("Events:", sum(train_data$status == 2), "\n")
    }

    # Generate lambda sequence
    if (is.null(lambda_seq)) {
        lambda_seq <- glmnet::glmnet(X, y,
                                   family = "cox", alpha = alpha)$lambda
        if (verbose) cat("Automatically generated", length(lambda_seq), "lambda values\n")
    }

    # Cross-validation
    cv_fit <- glmnet::cv.glmnet(X, y,
                              family = "cox", alpha = alpha, lambda = lambda_seq,
                              nfolds = nfolds, type.measure = "C")

    # Select optimal lambda
    best_lambda <- cv_fit$lambda.min
    best_lambda_1se <- cv_fit$lambda.1se

    if (verbose) {
        cat("Optimal lambda (min):", round(best_lambda, 6), "\n")
        cat("Optimal lambda (1se):", round(best_lambda_1se, 6), "\n")
        cat("Corresponding C-index (min):", round(max(cv_fit$cvm), 4), "\n")
    }

    # Fit final model using optimal lambda
    final_fit <- glmnet(X, y,
                       family = "cox",
                       alpha = alpha,
                       lambda = best_lambda)

    # Extract coefficients
    coefficients <- as.vector(coef(final_fit))
    names(coefficients) <- cov_names

    # Calculate number of non-zero coefficients
    n_nonzero <- sum(abs(coefficients) > 1e-8)

    if (verbose) {
        cat("Non-zero coefficients:", n_nonzero, "/", length(coefficients), "\n")
        cat("Sparsity:", round((length(coefficients) - n_nonzero) / length(coefficients) * 100, 1), "%\n")
    }

    return(list(
        model = final_fit,
        cv_model = cv_fit,
        coefficients = coefficients,
        best_lambda = best_lambda,
        best_lambda_1se = best_lambda_1se,
        n_nonzero = n_nonzero,
        training_info = list(
            n_samples = nrow(X),
            n_features = ncol(X),
            n_events = sum(train_data$status == 2),
            alpha = alpha,
            nfolds = nfolds
        )
    ))
}

#' Predict using Cox Lasso Model
#'
#' @param model_fit Trained Cox Lasso model
#' @param test_data Test data
#' @param cov_names Covariate names
#' @param use_1se Whether to use lambda.1se instead of lambda.min
#' @return Predicted risk scores
#' @export
predict_cox_lasso <- function(model_fit, test_data, cov_names, use_1se = FALSE) {

    # Prepare test data
    X_test <- as.matrix(test_data[, cov_names])

    # Select lambda
    lambda_use <- if (use_1se) model_fit$best_lambda_1se else model_fit$best_lambda

    # Predict linear predictor (risk score)
    predicted_risk <- predict(model_fit$model,
                             newx = X_test,
                             s = lambda_use,
                             type = "link")

    return(as.vector(predicted_risk))
}

#' Evaluate Cox Lasso Model Performance
#'
#' @param model_fit Trained Cox Lasso model
#' @param test_data Test data
#' @param cov_names Covariate names
#' @param true_beta True regression coefficients (if available)
#' @param verbose Whether to output detailed information
#' @return Evaluation results list
#' @export
evaluate_cox_lasso <- function(model_fit, test_data, cov_names, true_beta = NULL, verbose = TRUE) {

    # Cox Lasso model evaluation

    # Predict risk scores
    predicted_risk <- predict_cox_lasso(model_fit, test_data, cov_names)

    # Load evaluation functions if not already loaded
    # Assuming comprehensive_evaluation is available in the package

    # Comprehensive evaluation
    if (!is.null(true_beta)) {
        evaluation_results <- comprehensive_evaluation(
            predicted_risk = predicted_risk,
            estimated_beta = model_fit$coefficients,
            test_data = test_data,
            true_beta = true_beta
        )
    } else {
        # Calculate only prediction performance, not parameter accuracy
        cindex <- calculate_cindex(predicted_risk, test_data$time, test_data$status)
        evaluation_results <- list(
            cindex = cindex,
            summary = list(cindex = round(cindex, 4))
        )
    }

    if (verbose) {
        cat("C-index:", round(evaluation_results$cindex, 4), "\n")
        cat("Non-zero coefficients:", model_fit$n_nonzero, "\n")

        if (!is.null(evaluation_results$parameter_accuracy)) {
            cat("Parameter correlation:", round(evaluation_results$parameter_accuracy$correlation, 4), "\n")
            cat("F1 score:", round(evaluation_results$parameter_accuracy$f1_score, 4), "\n")
            cat("Precision:", round(evaluation_results$parameter_accuracy$precision, 4), "\n")
            cat("Recall:", round(evaluation_results$parameter_accuracy$recall, 4), "\n")
        }
    }

    # Add model specific info
    evaluation_results$model_info <- list(
        method = "Cox Lasso",
        best_lambda = model_fit$best_lambda,
        n_nonzero = model_fit$n_nonzero,
        training_samples = model_fit$training_info$n_samples
    )

    evaluation_results$predicted_risk <- predicted_risk

    return(evaluation_results)
}

#' Visualize Cox Lasso Model Results
#'
#' @param model_fit Trained Cox Lasso model
#' @param true_beta True coefficients (optional)
#' @param top_features Display top N important features
#' @export
plot_cox_lasso_results <- function(model_fit, true_beta = NULL, top_features = 20) {

    # Set graphics parameters
    par(mfrow = c(2, 2), mar = c(4, 4, 3, 2))

    # 1. Cross-validation curve
    plot(model_fit$cv_model, main = "Cox Lasso Cross-validation")
    abline(v = log(model_fit$best_lambda), col = "red", lty = 2)

    # 2. Coefficient path
    plot(model_fit$cv_model$glmnet.fit, xvar = "lambda", main = "Coefficient Path")
    abline(v = log(model_fit$best_lambda), col = "red", lty = 2)

    # 3. Coefficient bar plot
    coefs <- model_fit$coefficients
    nonzero_idx <- which(abs(coefs) > 1e-8)

    if (length(nonzero_idx) > 0) {
        # Select features to display
        if (length(nonzero_idx) > top_features) {
            # Sort by absolute value, select top features
            sorted_idx <- nonzero_idx[order(abs(coefs[nonzero_idx]), decreasing = TRUE)]
            show_idx <- sorted_idx[1:top_features]
        } else {
            show_idx <- nonzero_idx
        }

        coefs_show <- coefs[show_idx]
        names_show <- names(coefs_show)

        # Bar plot
        barplot(coefs_show,
                main = paste("Non-zero Coefficients (Top", length(show_idx), ")"),
                las = 2,
                cex.names = 0.8,
                col = ifelse(coefs_show > 0, "red", "blue"))
        abline(h = 0, lty = 2)
    }

    # 4. True vs Estimated Coefficients (if true values available)
    if (!is.null(true_beta)) {
        plot(true_beta, model_fit$coefficients,
             xlab = "True Coefficients", ylab = "Estimated Coefficients",
             main = "True vs Estimated Coefficients",
             pch = 16, col = rgb(0, 0, 1, 0.6))
        abline(0, 1, col = "red", lty = 2)

        # Add correlation coefficient
        cor_val <- cor(true_beta, model_fit$coefficients)
        text(min(true_beta), max(model_fit$coefficients),
             paste("Correlation:", round(cor_val, 3)),
             adj = c(0, 1))
    }

    # Reset graphics parameters
    par(mfrow = c(1, 1))
}
